[
  {
    "objectID": "talks/index.html",
    "href": "talks/index.html",
    "title": "Talks I’ve given",
    "section": "",
    "text": "Inference and analysis of synteny networks with syntenet\n\n\nWorkshop at #EuroBioc2022, the European Bioconductor annual conference\n\n\n\n\n\nSep 14, 2022\n\n\nFabrício Almeida-Silva\n\n\n\n\n\n\n\n\n\n\n\n\nBioinformatics in Modern Biology: computational genomics as a tool to unravel the soybean genome and gene regulation\n\n\nInvited speaker\n\n\n\n\n\nNov 22, 2021\n\n\nFabrício Almeida-Silva\n\n\n\n\n\n\n\n\n\n\n\n\nPrioritizing soybean resistance genes against fungal diseases by integrating GWAS and gene coexpression networks\n\n\nOral session at the 2021’s Plant Genomes in a Changing Environment conference\n\n\n\n\n\nOct 19, 2021\n\n\nFabrício Almeida-Silva\n\n\n\n\n\n\n\n\n\n\n\n\ncageminer: mining candidate genes by integrating GWAS and gene coexpression networks\n\n\nLightning Talk at #Bioc2021, the Bioconductor annual conference\n\n\n\n\n\nAug 6, 2021\n\n\nFabrício Almeida-Silva\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "talks/pgce2021/index.html",
    "href": "talks/pgce2021/index.html",
    "title": "Prioritizing soybean resistance genes against fungal diseases by integrating GWAS and gene coexpression networks",
    "section": "",
    "text": "Click here to access the slide presentation."
  },
  {
    "objectID": "talks/pgce2021/index.html#overview",
    "href": "talks/pgce2021/index.html#overview",
    "title": "Prioritizing soybean resistance genes against fungal diseases by integrating GWAS and gene coexpression networks",
    "section": "",
    "text": "Click here to access the slide presentation."
  },
  {
    "objectID": "talks/eurobioc2022/index.html",
    "href": "talks/eurobioc2022/index.html",
    "title": "Inference and analysis of synteny networks with syntenet",
    "section": "",
    "text": "Click here to access the slide presentations."
  },
  {
    "objectID": "talks/eurobioc2022/index.html#overview",
    "href": "talks/eurobioc2022/index.html#overview",
    "title": "Inference and analysis of synteny networks with syntenet",
    "section": "",
    "text": "Click here to access the slide presentations."
  },
  {
    "objectID": "software/index.html",
    "href": "software/index.html",
    "title": "Software & Data Products",
    "section": "",
    "text": "Below you can find a list of software tools and databases/web applications I have developed.\n\n\n\n\n\n\n\n\n\n\nPackage\n\n\n\n \n\n\n\nDescription\n\n\n\nType\n\n\n\n\n\n\n\n\nAngioWGD\n\n\n\n\n\nAn R package that contains a Shiny app to explore whole-genome duplication (WGD) events identified and dated in 470 angiosperm genomes. \n\n\ndatabase\n\n\n\n\n\n\ndoubletrouble\n\n\n\n\n\nAn R package to to identify duplicated genes from whole-genome protein sequences and classify them based on their modes of duplication. The duplication modes are i. segmental duplication (SD); ii. tandem duplication (TD); iii. proximal duplication (PD); iv. transposed duplication (TRD) and; v. dispersed duplication (DD). Transposon-derived duplicates (TRD) can be further subdivided into rTRD (retrotransposon-derived duplication) and dTRD (DNA transposon-derived duplication). Users can also calculate substitution rates per substitution site (i.e., Ka and Ks) from duplicate pairs, find peaks in Ks distributions with Gaussian Mixture Models (GMMs), and classify gene pairs into age groups based on Ks peaks. \n\n\nsoftware\n\n\n\n\n\n\nHybridExpress\n\n\n\n\n\nAn R package to perform comparative transcriptomics analysis of hybrids (or allopolyploids) relative to their progenitor species. The package features functions to perform exploratory analyses of sample grouping, identify differentially expressed genes in hybrids relative to their progenitors, classify genes in expression categories (N = 12) and classes (N = 5), and perform functional analyses. We also provide users with graphical functions for the seamless creation of publication-ready figures that are commonly used in the literature. \n\n\nsoftware\n\n\n\n\n\n\ncogeqc\n\n\n\n\n\nAn R package to facilitate systematic quality checks on standard comparative genomics analyses, and to help researchers detect issues and select the most suitable parameters for each data set. cogeqc can be used to asses: i. genome assembly and annotation quality with BUSCOs and comparisons of statistics with publicly available genomes on the NCBI; ii. orthogroup inference using a protein domain-based approach and; iii. synteny detection using synteny network properties. cogeqc also offers visualization functions to explore QC summary statistics. \n\n\nsoftware\n\n\n\n\n\n\nSoybeanExpressionAtlas\n\n\n\n\n\nAn R package that contains a Shiny app to explore and download data from the Soybean Expression Atlas, a database of &gt;5000 bulk RNA-seq samples from different soybean tissues at several different conditions. \n\n\ndatabase\n\n\n\n\n\n\nbears\n\n\n\n\n\nAn R package with an RNA-seq pipeline to create gene expression atlases from publicly available bulk RNA-seq data in NCBI’s SRA. Users can download raw reads, preprocess them, map to a reference genome and transcriptome, and quantify the expression at the gene and transcript levels. The goal of bears is to make RNA-seq data analysis pipelines reproducible, with a framework built on state-of-the art methods and software tools, and all of that in the comfort of an R session. \n\n\nsoftware\n\n\n\n\n\n\nplanttfhunter\n\n\n\n\n\nAn R package to identify plant transcription factors (TFs) from protein sequence data and classify them into families and subfamilies using the classification scheme implemented in PlantTFDB. TFs are identified using pre-built hidden Markov model profiles for DNA-binding domains. Then, auxiliary and forbidden domains are used with DNA-binding domains to classify TFs into families and subfamilies (when applicable). Currently, TFs can be classified in 58 different TF families/subfamilies. \n\n\nsoftware\n\n\n\n\n\n\nmagrene\n\n\n\n\n\nAn R package for the identification and analysis of graph motifs in (duplicated) gene regulatory networks (GRNs), including lambda, V, PPI V, delta, and bifan motifs. GRNs can be tested for motif enrichment by comparing motif frequencies to a null distribution generated from degree-preserving simulated GRNs. Motif frequencies can be analyzed in the context of gene duplications to explore the impact of small-scale and whole-genome duplications on gene regulatory networks. Finally, users can calculate interaction similarity for gene pairs based on the Sorensen-Dice similarity index. \n\n\nsoftware\n\n\n\n\n\n\nsyntenet\n\n\n\n\n\nAn R package to infer synteny networks from whole-genome protein sequences and analyze them. Anchor pairs are detected with the MCScanX algorithm, which was ported to this package with the Rcpp framework for R and C++ integration. Anchor pairs from synteny analyses are treated as an undirected unweighted graph (i.e., a synteny network), and users can perform: i. network clustering; ii. phylogenomic profiling (by identifying which species contain which clusters) and; iii. microsynteny-based phylogeny reconstruction with maximum likelihood. \n\n\nsoftware\n\n\n\n\n\n\nSoyPestGCN\n\n\n\n\n\nAn R package that contains a Shiny app to let users explore a gene coexpression network inferred from RNA-seq data comprising soybean tissues infested with pests (i.e., insects and nematodes). \n\n\ndatabase\n\n\n\n\n\n\nSoyFungiGCN\n\n\n\n\n\nAn R package that contains a Shiny app to let users explore a gene coexpression network inferred from RNA-seq data comprising soybean tissues infected with phytopathogenic fungi. \n\n\ndatabase\n\n\n\n\n\n\ncageminer\n\n\n\n\n\nAn R package to integrate GWAS-derived SNPs and coexpression networks to mine candidate genes associated with a particular phenotype using guide genes. Candidate genes can be scored and ranked to select promising targets for downstream experiments. \n\n\nsoftware\n\n\n\n\n\n\nBioNERO\n\n\n\n\n\nAn R package that aims to facilitate network analyses by integrating all standard analysis steps, including data preprocessing, inference of gene regulatory and coexpression network from expression data, functional analyses, and intra/interspecies network comparisons. \n\n\nsoftware\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "My blog",
    "section": "",
    "text": "Here, I write about R, Bioconductor, open science, reproducible research, and more.\n\n\n\n\n\n\n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nParquet is the new TSV\n\n\n\nbioinformatics\n\ndatabase\n\n\n\nLarger-than-memory data access with .parquet files\n\n\n\n\n\nJun 5, 2025\n\n\nFabrício Almeida-Silva\n\n\n\n\n\n\n\n\n\n\n\n\nWhere can I publish a paper describing my Bioconductor package?\n\n\n\nbioinformatics\n\nreproducible research\n\nbioconductor\n\nscientific writing\n\nrstats\n\n\n\nCheck out where Bioc developers have published their papers\n\n\n\n\n\nJun 12, 2023\n\n\nFabrício Almeida-Silva\n\n\n\n\n\n\n\n\n\n\n\n\nUpgrading R version with all your packages\n\n\n\nrstats\n\nproject management\n\n\n\nLearn how to do a painless upgrade of your R version\n\n\n\n\n\nMay 6, 2022\n\n\nFabrício Almeida-Silva\n\n\n\n\n\n\n\n\n\n\n\n\nPushing Docker images to Docker Hub\n\n\n\nproject management\n\nbioinformatics\n\ndocker\n\nvirtualization\n\nreproducible research\n\n\n\nKeeping your images in a Docker Hub repo will make your life easier\n\n\n\n\n\nDec 1, 2021\n\n\nFabrício Almeida-Silva\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/2022-01-03-bioc_publications/index.html",
    "href": "blog/2022-01-03-bioc_publications/index.html",
    "title": "Where can I publish a paper describing my Bioconductor package?",
    "section": "",
    "text": "When I developed BioNERO, my first R/Bioconductor package, I didn’t know to which journals I could submit the paper describing it. Since then, I’ve seen many other R developers that have faced the same issue. To help solve this problem, here I will guide you on how to do some web scraping to find out the main journals where Bioc developers publish papers describing their packages."
  },
  {
    "objectID": "blog/2022-01-03-bioc_publications/index.html#motivation",
    "href": "blog/2022-01-03-bioc_publications/index.html#motivation",
    "title": "Where can I publish a paper describing my Bioconductor package?",
    "section": "",
    "text": "When I developed BioNERO, my first R/Bioconductor package, I didn’t know to which journals I could submit the paper describing it. Since then, I’ve seen many other R developers that have faced the same issue. To help solve this problem, here I will guide you on how to do some web scraping to find out the main journals where Bioc developers publish papers describing their packages."
  },
  {
    "objectID": "blog/2022-01-03-bioc_publications/index.html#extracting-citation-information-from-bioconductors-browsable-code-base",
    "href": "blog/2022-01-03-bioc_publications/index.html#extracting-citation-information-from-bioconductors-browsable-code-base",
    "title": "Where can I publish a paper describing my Bioconductor package?",
    "section": "Extracting citation information from Bioconductor’s browsable code base",
    "text": "Extracting citation information from Bioconductor’s browsable code base\nBioconductor offers a browsable code base that lets users explore git repositories and search code in all Bioconductor packages. If we go to the Code Search page and search journal f:CITATION, we will get a list of all CITATION files (where developers include citation information for their packages) that include the string “journal”.\nKnowing that, we can do some web scraping using the rvest package to extract such information for all packages and parse it into a nicely-formatted data frame.\n\n# Load required packages\nlibrary(tidyverse)\nlibrary(rvest)\n\n# Get URL of the search \"journal f:CITATION\"\nurl &lt;- \"https://code.bioconductor.org/search/search?q=journal%20f%3aCITATION\"\nn &lt;- 2000 # number of files to show\n\n# Get list of tables containing journal names\njournal_list &lt;- rvest::read_html(paste0(url, \"&num=\", n)) |&gt;\n    rvest::html_table()\n\n# Parse list of data frames into a large, tidy list\njournal_df &lt;- Reduce(rbind, lapply(seq_along(journal_list), function(x) {\n    \n    df &lt;- journal_list[[x]]\n    \n    # Package name\n    pkg &lt;- gsub(\":.*\", \"\", names(df)[1])\n    \n    names(df) &lt;- \"entries\"\n    df &lt;- as.data.frame(df) |&gt; \n        # 1) Keep only rows containing 'journal=' or 'journal ='\n        filter(str_detect(entries, \"journal\\\\s*=\")) |&gt;\n        # 2) Get journal name (remove quotation marks, whitespace, commas, etc)\n        mutate(\n            journal = str_replace_all(entries, \".*=\", \"\"),\n            journal = str_replace_all(journal, '\\\\\\\"', ''),\n            journal = str_replace_all(journal, \"'\", ''),\n            journal = str_replace_all(journal, \"\\\\.\", \"\"),\n            journal = str_squish(journal),\n            journal = str_to_upper(journal),\n            journal = str_replace_all(journal, \",$\", \"\"),\n            journal = str_replace_all(journal, \"\\\\)\", \"\"),\n            journal = str_replace_all(journal, \"\\\\(\", \"\"),\n            journal = str_replace_all(journal, \"\\\\{\", \"\"),\n            journal = str_replace_all(journal, \"\\\\}\", \"\")\n        ) |&gt;\n        select(journal)\n    \n    # Add a column named `package` containing package name\n    if(nrow(df) &gt; 0) {\n        df &lt;- df |&gt;\n            mutate(package = pkg)\n    }\n    \n    return(df)\n}))\n\n# Taking a look at the first rows\nhead(journal_df)\n\n             journal           package\n1     BIOINFORMATICS        cytomapper\n2 SCIENTIFIC REPORTS      IsoCorrectoR\n3     BIOINFORMATICS             Rtpca\n4     BIOINFORMATICS transcriptogramer\n5     BIOINFORMATICS               ACE\n6     BIOINFORMATICS          limmaGUI\n\n\nNow, because CITATION files are created manually by developers, a big (and expected) problem is the lack of standardization. This leads to different developers referring to the same journal by different names (e.g., Nature Methods and Nat Methods, Nucleic Acids Research and NAR, etc). You can see that yourself by executing sort(unique(journal_df$journal)). While I can never expect to fix this problem completely (especially if you are reading this post in the future and new packages have been added), below is my attempt to fix most of the inconsistencies. I will probably miss some strange exceptions, but I guess I can live with it, right?\n\n# 'Journals' to remove (these are not actually journals)\nto_remove &lt;- c(\n    \"\", \"07\", \"1\", \"10\", as.character(2010:2023), \"2022-2032\",\n    \"IN REVIEW\", \"IN PREPARATION\", \"JOURNAL\", \"MANUSCRIPT IN PREPARATION\",\n    \"TBA\", \"TBD\", \"UNDER REVIEW\", \"UNIVERSITY OF REGENSBURG\",\n    \"BIOCONDUCTOR\", \"SUBMITTED\", \"MEDRXIV\", \"BIORXIV\", \"PREPRINT\", \"ARXIV\"\n)\n\n# Standardize names\njournal_df_clean &lt;- journal_df |&gt;\n    filter(!journal %in% to_remove) |&gt;\n    mutate(\n        journal = str_replace_all(journal, c(\n            \"ALBANY NY.*\" = \"\",\n            \"ALGORITHMS MOL BIO\" = \"ALGORITHMS FOR MOLECULAR BIOLOGY\",\n            \"ANAL CHEM\" = \"ANALYTICAL CHEMISTRY\",\n            \"ANN APPL STAT\" = \"ANNALS OF APPLIED STATISTICS\",\n            \"PREPRINT.*\" = \"\",\n            \"BIONFORMATICS JOURNAL\" = \"BIOINFORMATICS\",\n            \"OXFORD, ENGLAND\" = \"\",\n            \"ACCEPTED\" = \"\",\n            \"BMC SYST BIOL\" = \"BMC SYSTEMS BIOLOGY\",\n            \"COMPUT METHODS PROGRAMS BIOMED\" = \"COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE\",\n            \"CYTOMETRY A\" = \"CYTOMETRY PART A\",\n            \"EPIGENETICS CHROMATIN\" = \"EPIGENETICS & CHROMATIN\",\n            \"F1000.*\" = \"F1000RESEARCH\",\n            \"FRONT BIOL\" = \"FRONTIERS IN BIOLOGY\",\n            \"GENOME BIOL$\" = \"GENOME BIOLOGY\",\n            \"GENOME RES$\" = \"GENOME RESEARCH\",\n            \", CODE SNIPPETS\" = \"\",\n            \", SERIES B\" = \"\",\n            \"J MACH LEARN RES\" = \"JOURNAL OF MACHINE LEARNING RESEARCH\",\n            \"METHODS MOL BIO\" = \"METHODS IN MOLECULAR BIOLOGY\",\n            \"MOL SYST BIOL\" = \"MOLECULAR SYSTEMS BIOLOGY\",\n            \"NAT BIOTECH.*\" = \"NATURE BIOTECHNOLOGY\",\n            \"NAT COMM.*\" = \"NATURE COMMUNICATIONS\",\n            \"NAT GENET\" = \"NATURE GENETICS\",\n            \"NAT IMMUNOL\" = \"NATURE IMMUNOLOGY\",\n            \"NAT METH\" = \"NATURE METHODS\",\n            \"NPG SYST BIOL APPL\" = \"NPG SYSTEMS BIOLOGY AND APPLICATIONS\",\n            \" GKV873\" = \"\",\n            \"NUCL ACIDS RES$\" = \"NUCLEIC ACIDS RESEARCH\",\n            \"NUCLEIC ACIDS RES$\" = \"NUCLEIC ACIDS RESEARCH\",\n            \"DATABASE ISSUE\" = \"\",\n            \"OXFORD BIOINFORMATICS\" = \"BIOINFORMATICS\",\n            \"PLOS COMPUT BIOL\" = \"PLOS COMPUTATIONAL BIOLOGY\",\n            \"PLOS COMPUTAT BIOL\" = \"PLOS COMPUTATIONAL BIOLOGY\",\n            \"PROC NATL ACAD SCI.*\" = \"PNAS\",\n            \"PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES.*\" = \"PNAS\",\n            \"STAT APPL GENET MOL BIOL\" = \"STATISTICAL APPLICATIONS IN GENETICS AND MOLECULAR BIOLOGY\"\n        )\n        ),\n        journal = str_squish(journal)\n    )\n\n# Taking a look at the first rows\nhead(journal_df_clean)\n\n             journal           package\n1     BIOINFORMATICS        cytomapper\n2 SCIENTIFIC REPORTS      IsoCorrectoR\n3     BIOINFORMATICS             Rtpca\n4     BIOINFORMATICS transcriptogramer\n5     BIOINFORMATICS               ACE\n6     BIOINFORMATICS          limmaGUI\n\n\nThe final data frame of packages and journals where they published their papers can be explored below:"
  },
  {
    "objectID": "blog/2022-01-03-bioc_publications/index.html#summary-stats",
    "href": "blog/2022-01-03-bioc_publications/index.html#summary-stats",
    "title": "Where can I publish a paper describing my Bioconductor package?",
    "section": "Summary stats",
    "text": "Summary stats\nNow, let’s count the frequency of packages in each journal and show the top 20 journals based number of the number of papers associated with Bioc packages.\n\n# Get top 20 journals in number of papers associated with Bioc pkgs\ncitation_stats &lt;- journal_df_clean %&gt;%\n    count(journal) %&gt;%\n    arrange(-n) %&gt;%\n    slice_head(n = 20)\n\ncitation_stats\n\n                                                      journal   n\n1                                              BIOINFORMATICS 303\n2                                          BMC BIOINFORMATICS 101\n3                                      NUCLEIC ACIDS RESEARCH  71\n4                                              GENOME BIOLOGY  61\n5                                               F1000RESEARCH  34\n6                                              NATURE METHODS  30\n7                                                BMC GENOMICS  25\n8                                       NATURE COMMUNICATIONS  24\n9                                  PLOS COMPUTATIONAL BIOLOGY  22\n10                                                   PLOS ONE  22\n11                                            GENOME RESEARCH  13\n12                                       ANALYTICAL CHEMISTRY  11\n13                                              BIOSTATISTICS  10\n14                                BRIEFINGS IN BIOINFORMATICS   9\n15                                       NATURE BIOTECHNOLOGY   9\n16                               JOURNAL OF PROTEOME RESEARCH   8\n17                                  MOLECULAR SYSTEMS BIOLOGY   8\n18                                            NATURE GENETICS   8\n19                                                       PNAS   8\n20 STATISTICAL APPLICATIONS IN GENETICS AND MOLECULAR BIOLOGY   7\n\n\nExploring it visually:\n\n# Read figure with Bioc logo\nbioc_logo &lt;- png::readPNG(\n    here::here(\"blog\", \"2022-01-03-bioc_publications\", \"featured-bioc.png\"), \n    native = TRUE\n)\n\n# Define plotting params\nlast_updated &lt;- format(Sys.Date(), \"%Y-%m-%d\")\nxmax &lt;- max(citation_stats$n) + 30\nxmax &lt;- round(xmax / 10) * 10\n\n# Plot data\nggplot(citation_stats, aes(x = n, y = reorder(journal, n))) +\n    geom_col() +\n    geom_text(aes(label = n), hjust = -0.3) +\n    xlim(0, xmax) +\n    labs(\n        title = \"Where are papers associated with BioC packages published?\",\n        subtitle = paste0(\"Last update: \", last_updated),\n        x = \"Number of papers\", y = \"\"\n    ) +\n    theme_bw() +\n    patchwork::inset_element(\n        bioc_logo,\n        left = 0.5,\n        top = 0.55,\n        right = 0.95,\n        bottom = 0.3\n    ) +\n    theme_void()\n\n\n\n\n\n\n\n\nAnd voilà! In case you want to explore the whole table, here it is:"
  },
  {
    "objectID": "blog/2022-01-03-bioc_publications/index.html#session-information",
    "href": "blog/2022-01-03-bioc_publications/index.html#session-information",
    "title": "Where can I publish a paper describing my Bioconductor package?",
    "section": "Session information",
    "text": "Session information\nThis post was created under the following conditions:\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.3.0 (2023-04-21)\n os       Ubuntu 20.04.5 LTS\n system   x86_64, linux-gnu\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/Brussels\n date     2023-06-13\n pandoc   3.1.1 @ /usr/lib/rstudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n BiocManager   1.30.20 2023-02-24 [1] CRAN (R 4.3.0)\n BiocStyle     2.28.0  2023-04-25 [1] Bioconductor\n bslib         0.4.2   2022-12-16 [1] CRAN (R 4.3.0)\n cachem        1.0.8   2023-05-01 [1] CRAN (R 4.3.0)\n cli           3.6.1   2023-03-23 [1] CRAN (R 4.3.0)\n colorspace    2.1-0   2023-01-23 [1] CRAN (R 4.3.0)\n crosstalk     1.2.0   2021-11-04 [1] CRAN (R 4.3.0)\n curl          5.0.0   2023-01-12 [1] CRAN (R 4.3.0)\n digest        0.6.31  2022-12-11 [1] CRAN (R 4.3.0)\n dplyr       * 1.1.2   2023-04-20 [1] CRAN (R 4.3.0)\n DT            0.27    2023-01-17 [1] CRAN (R 4.3.0)\n ellipsis      0.3.2   2021-04-29 [1] CRAN (R 4.3.0)\n evaluate      0.20    2023-01-17 [1] CRAN (R 4.3.0)\n fansi         1.0.4   2023-01-22 [1] CRAN (R 4.3.0)\n farver        2.1.1   2022-07-06 [1] CRAN (R 4.3.0)\n fastmap       1.1.1   2023-02-24 [1] CRAN (R 4.3.0)\n forcats     * 1.0.0   2023-01-29 [1] CRAN (R 4.3.0)\n generics      0.1.3   2022-07-05 [1] CRAN (R 4.3.0)\n ggplot2     * 3.4.2   2023-04-03 [1] CRAN (R 4.3.0)\n glue          1.6.2   2022-02-24 [1] CRAN (R 4.3.0)\n gtable        0.3.3   2023-03-21 [1] CRAN (R 4.3.0)\n here          1.0.1   2020-12-13 [1] CRAN (R 4.3.0)\n hms           1.1.3   2023-03-21 [1] CRAN (R 4.3.0)\n htmltools     0.5.5   2023-03-23 [1] CRAN (R 4.3.0)\n htmlwidgets   1.6.2   2023-03-17 [1] CRAN (R 4.3.0)\n httr          1.4.5   2023-02-24 [1] CRAN (R 4.3.0)\n jquerylib     0.1.4   2021-04-26 [1] CRAN (R 4.3.0)\n jsonlite      1.8.4   2022-12-06 [1] CRAN (R 4.3.0)\n knitr         1.42    2023-01-25 [1] CRAN (R 4.3.0)\n labeling      0.4.2   2020-10-20 [1] CRAN (R 4.3.0)\n lifecycle     1.0.3   2022-10-07 [1] CRAN (R 4.3.0)\n lubridate   * 1.9.2   2023-02-10 [1] CRAN (R 4.3.0)\n magrittr      2.0.3   2022-03-30 [1] CRAN (R 4.3.0)\n munsell       0.5.0   2018-06-12 [1] CRAN (R 4.3.0)\n patchwork     1.1.2   2022-08-19 [1] CRAN (R 4.3.0)\n pillar        1.9.0   2023-03-22 [1] CRAN (R 4.3.0)\n pkgconfig     2.0.3   2019-09-22 [1] CRAN (R 4.3.0)\n png           0.1-8   2022-11-29 [1] CRAN (R 4.3.0)\n purrr       * 1.0.1   2023-01-10 [1] CRAN (R 4.3.0)\n R6            2.5.1   2021-08-19 [1] CRAN (R 4.3.0)\n readr       * 2.1.4   2023-02-10 [1] CRAN (R 4.3.0)\n rlang         1.1.1   2023-04-28 [1] CRAN (R 4.3.0)\n rmarkdown     2.21    2023-03-26 [1] CRAN (R 4.3.0)\n rprojroot     2.0.3   2022-04-02 [1] CRAN (R 4.3.0)\n rstudioapi    0.14    2022-08-22 [1] CRAN (R 4.3.0)\n rvest       * 1.0.3   2022-08-19 [1] CRAN (R 4.3.0)\n sass          0.4.5   2023-01-24 [1] CRAN (R 4.3.0)\n scales        1.2.1   2022-08-20 [1] CRAN (R 4.3.0)\n sessioninfo   1.2.2   2021-12-06 [1] CRAN (R 4.3.0)\n stringi       1.7.12  2023-01-11 [1] CRAN (R 4.3.0)\n stringr     * 1.5.0   2022-12-02 [1] CRAN (R 4.3.0)\n tibble      * 3.2.1   2023-03-20 [1] CRAN (R 4.3.0)\n tidyr       * 1.3.0   2023-01-24 [1] CRAN (R 4.3.0)\n tidyselect    1.2.0   2022-10-10 [1] CRAN (R 4.3.0)\n tidyverse   * 2.0.0   2023-02-22 [1] CRAN (R 4.3.0)\n timechange    0.2.0   2023-01-11 [1] CRAN (R 4.3.0)\n tzdb          0.3.0   2022-03-28 [1] CRAN (R 4.3.0)\n utf8          1.2.3   2023-01-31 [1] CRAN (R 4.3.0)\n vctrs         0.6.2   2023-04-19 [1] CRAN (R 4.3.0)\n withr         2.5.0   2022-03-03 [1] CRAN (R 4.3.0)\n xfun          0.39    2023-04-20 [1] CRAN (R 4.3.0)\n xml2          1.3.4   2023-04-27 [1] CRAN (R 4.3.0)\n yaml          2.3.7   2023-01-23 [1] CRAN (R 4.3.0)\n\n [1] /home/faalm/R/x86_64-pc-linux-gnu-library/4.3\n [2] /usr/local/lib/R/site-library\n [3] /usr/lib/R/site-library\n [4] /usr/lib/R/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "blog/2025-06-05-parquet-is-the-new-csv/index.html",
    "href": "blog/2025-06-05-parquet-is-the-new-csv/index.html",
    "title": "Parquet is the new TSV",
    "section": "",
    "text": "For programming languages that store data in memory (e.g. R and Python), working with large data files can be a problem. For example, if you need to subset a few rows from a large table stored in a 5 GB TSV/CSV file, you will first need to read the entire table, then subset the rows you want. If your data is larger than your memory capacity, reading the entire data set is not possible. Apache Parquet is a column-oriented file format (similar to TSV/CSV) designed for efficient data storage and retrieval, and it can be used by packages such as arrow to analyze larger-than-memory data sets. Here, I will demonstrate the advantages of storing large data in Parquet files (compared to TSV/CSV files), and benchmark data retrieval using Parquet files and other alternatives.\n\n# Load required packages\nlibrary(tidyverse)\nlibrary(arrow)\nlibrary(duckdb)"
  },
  {
    "objectID": "blog/2025-06-05-parquet-is-the-new-csv/index.html#motivation",
    "href": "blog/2025-06-05-parquet-is-the-new-csv/index.html#motivation",
    "title": "Parquet is the new TSV",
    "section": "",
    "text": "For programming languages that store data in memory (e.g. R and Python), working with large data files can be a problem. For example, if you need to subset a few rows from a large table stored in a 5 GB TSV/CSV file, you will first need to read the entire table, then subset the rows you want. If your data is larger than your memory capacity, reading the entire data set is not possible. Apache Parquet is a column-oriented file format (similar to TSV/CSV) designed for efficient data storage and retrieval, and it can be used by packages such as arrow to analyze larger-than-memory data sets. Here, I will demonstrate the advantages of storing large data in Parquet files (compared to TSV/CSV files), and benchmark data retrieval using Parquet files and other alternatives.\n\n# Load required packages\nlibrary(tidyverse)\nlibrary(arrow)\nlibrary(duckdb)"
  },
  {
    "objectID": "blog/2025-06-05-parquet-is-the-new-csv/index.html#example-data",
    "href": "blog/2025-06-05-parquet-is-the-new-csv/index.html#example-data",
    "title": "Parquet is the new TSV",
    "section": "Example data",
    "text": "Example data\nPLAZA is a database for plant comparative genomics data. Among many important features and data resources, PLAZA provides orthologous relationships for plant genes using differnent ‘orthology types’. Here, I will use orthologous genes obtained with the best-hit-and-inparalogs (BHI) type. This is a large (3 GB) CSV file containing the orthologs for all genes in all species in PLAZA Dicots 5.0. For example, if you have a gene of interest in Arabidopsis thaliana, you can use this file to find the corresponding (orthologous) gene(s) in other plants for comparative studies.\nLet’s first download the file to a temporary directory.\n\n# Download file\noptions(timeout = 1e6) # download might take a while\n\ncsv_file &lt;- file.path(tempdir(), \"plaza_dicots_bhif.csv.gz\")\ndownload.file(\n    url = \"https://ftp.psb.ugent.be/pub/plaza/plaza_public_dicots_05/IntegrativeOrthology/integrative_orthology.BHIF.csv.gz\",\n    destfile = csv_file\n)"
  },
  {
    "objectID": "blog/2025-06-05-parquet-is-the-new-csv/index.html#from-csv-to-parquet",
    "href": "blog/2025-06-05-parquet-is-the-new-csv/index.html#from-csv-to-parquet",
    "title": "Parquet is the new TSV",
    "section": "From CSV to Parquet",
    "text": "From CSV to Parquet\nTo create a Parquet file, we could read the CSV file to the R session and export it as .parquet file using the arrow or nanoparquet packages. This works well if you have access to an HPC or a powerful server. If you don’t have access to a machine with more memory, don’t panic: you can use the duckdb package to create a Parquet file from a CSV file without having to load it first. This can be achieved with the following code:\n\n# Directly convert CSV to Parquet using {duckdb}\ncon &lt;- dbConnect(duckdb())\nparquet_file &lt;- file.path(tempdir(), \"plaza_dicots_bhif.parquet\")\n\nquery &lt;- paste0(\"\n  COPY (SELECT * FROM '\", csv_file, \"') \n  TO '\", parquet_file, \"' (FORMAT PARQUET)\n\")\ndbExecute(con, query)\ndbDisconnect(con)\n\nIn terms of storage, a Parquet file is comparable to a gzipped CSV file.\n\n# Inspect file sizes\ndata.frame(\n    Format = c(\"CSV\", \"Parquet\"),\n    Size = fs::file_size(c(csv_file, parquet_file)),\n    row.names = NULL\n)\n\n   Format  Size\n1     CSV 3.03G\n2 Parquet 3.67G"
  },
  {
    "objectID": "blog/2025-06-05-parquet-is-the-new-csv/index.html#larger-than-memory-data-access-with-arrow",
    "href": "blog/2025-06-05-parquet-is-the-new-csv/index.html#larger-than-memory-data-access-with-arrow",
    "title": "Parquet is the new TSV",
    "section": "Larger-than-memory data access with {arrow}",
    "text": "Larger-than-memory data access with {arrow}\nOnce you have tabular data in a Parquet file, you can use the arrow package to ‘connect’ to the file, perform some data transformation (e.g., filter rows, subset columns, summarize data by groups, etc) using tidyverse verbs, and read only the output of the data transformation. If your familiar with SQL, this is similar to performing SQL queries without loading the data in memory.\nTo demonstrate how this works, we will extract orthologs (i.e., best-hits-and-inparalogs) of the gene AT2G14610, which encodes a pathogenesis-related protein 1 (PR-1) in Arabidopsis thaliana.\n\n# Connect to the Parquet file\nbhi &lt;- arrow::open_dataset(parquet_file)\nbhi\n\nFileSystemDataset with 1 Parquet file\n4 columns\n#query_gene: string\nquery_species: string\northologous_gene: string\northologous_species: string\n\n\nOnce we connect to the Parquet file, we can see that it contains a table with four columns named #query_gene, query_species, orthologous_gene, and orthologous_species. Now, we will filter the table to keep only rows that have ‘AT2G14610’ in column #query_gene, and collect the results to the R session.\n\n# Extract best-hits-and-inparalogs of 'AT2G14610'\npr1_orthologs &lt;- bhi |&gt;\n    filter(`#query_gene` == \"AT2G14610\") |&gt;\n    collect()\n\nhead(pr1_orthologs)\n\n# A tibble: 6 × 4\n  `#query_gene` query_species orthologous_gene               orthologous_species\n  &lt;chr&gt;         &lt;chr&gt;         &lt;chr&gt;                          &lt;chr&gt;              \n1 AT2G14610     ath           AagrBONN_evm.TU.Sc2ySwM_228.2… aag                \n2 AT2G14610     ath           Aa31LG2G16880                  aar                \n3 AT2G14610     ath           Aa31LG2G16870                  aar                \n4 AT2G14610     ath           Atru.chr5.2212                 acertr             \n5 AT2G14610     ath           Actinidia00340                 ach                \n6 AT2G14610     ath           AL3G46130                      aly                \n\n\nBrilliant, isn’t it? Using Parquet files, we can seamlessly subset a table that is too large to fit in memory, solving the problem of larger-than-memory data analysis."
  },
  {
    "objectID": "blog/2025-06-05-parquet-is-the-new-csv/index.html#benchmark",
    "href": "blog/2025-06-05-parquet-is-the-new-csv/index.html#benchmark",
    "title": "Parquet is the new TSV",
    "section": "Benchmark",
    "text": "Benchmark\nNow, you might be asking yourself:\n\nDo I need Parquet files? Why not extract the rows I want from the CSV file using Bash code?\n\nThat is indeed possible. In your terminal, you can use Bash code to read the CSV file line by line and search for rows that match our condition (i.e., ‘AT2G14610’ in column #query_gene). The Bash code would look something like this:\n\nzcat file.csv.gz | grep -E '^#query|^AT2G14610' &gt; filtered.csv\n\nLet’s compare the performance of the Bash-based approach with the arrow-based approach. Of note, the .csv.gz file from PLAZA is actually a TSV file, not CSV, but that doesn’t impact performance.\n\n# Wrapper function for the Bash-based approach\nfilter_bash &lt;- function() {\n    outfile &lt;- file.path(tempdir(), \"output.tsv\")\n    args &lt;- c(csv_file, \" | grep -E '^#query|^AT2G14610' &gt; \", outfile)\n    system2(\"zcat\", args = args)\n    \n    df &lt;- read_tsv(outfile, show_col_types = FALSE) |&gt; as.data.frame()\n    return(df)\n}\n\n# Benchmark\nbnch &lt;- bench::mark(\n    arrow = bhi |&gt;\n        filter(`#query_gene` == \"AT2G14610\") |&gt;\n        collect() |&gt;\n        as.data.frame(),\n    bash = filter_bash()\n)\n\nbnch\n\n# A tibble: 2 × 6\n  expression      min   median `itr/sec` mem_alloc `gc/sec`\n  &lt;bch:expr&gt; &lt;bch:tm&gt; &lt;bch:tm&gt;     &lt;dbl&gt; &lt;bch:byt&gt;    &lt;dbl&gt;\n1 arrow        29.8ms   33.8ms   27.2       58.6KB     4.53\n2 bash          58.3s    58.3s    0.0171     1.8MB     0   \n\n\nThe benchmark shows that the arrow-based approach (using Parquet files) is much faster than the Bash approach (milliseconds vs one minute!). Hence, developers and maintainers of databases that provide users with large data files should consider providing Parquet files besides traditional CSV/TSV files. In the era of machine learning, AI, and large data, I believe this will make data analysis workflows much faster and more efficient."
  },
  {
    "objectID": "about/index.html",
    "href": "about/index.html",
    "title": "About me",
    "section": "",
    "text": "VIB Center for Plant Systems Biology  Department of Plant Biotechnology and Bioinformatics  Ghent University  Technologiepark 71, 9052 Ghent, Belgium \nEmail: fabricio.almeidasilva@psb.vib-ugent.be  Personal email: fabricio_almeidasilva@hotmail.com"
  },
  {
    "objectID": "about/index.html#contact",
    "href": "about/index.html#contact",
    "title": "About me",
    "section": "",
    "text": "VIB Center for Plant Systems Biology  Department of Plant Biotechnology and Bioinformatics  Ghent University  Technologiepark 71, 9052 Ghent, Belgium \nEmail: fabricio.almeidasilva@psb.vib-ugent.be  Personal email: fabricio_almeidasilva@hotmail.com"
  },
  {
    "objectID": "about/index.html#background",
    "href": "about/index.html#background",
    "title": "About me",
    "section": "Background",
    "text": "Background\nFor my undergrad studies, I attended the State University of Northern Rio de Janeiro (UENF) to study Biological Sciences, graduating with distinction (magna cum laude) in 2019. Like many great universities in Brazil, UENF stands out due to its strong Scientific Initiation program that allows undergrad students to start a research project at an early stage of their careers. Thanks to this program, I joined the lab of Dr. Thiago Venancio as an undergrad trainee. Thiago has been a truly exceptional mentor, and he supervised me in a project that aimed at exploring transcriptional regulation in soybean (Glycine max) using gene coexpression networks inferred from a large compendium of RNA-seq set with &gt;1000 samples (which later became the Soybean Expression Atlas).\n\n\n\n\nSunset at the whistle-shaped Convention Center at the State University of Northern Rio de Janeiro (UENF). This building was designed by the renowned Brazilian architect Oscar Niemeyer.\n\n\n\n\nIn 2020, I joined a Master’s program in Plant Biotechnology at UENF, still under the supervision of Dr. Thiago Venancio, where I developed a statistical framework to integrate data from genome-wide association studies (GWAS) and RNA-seq experiments, particularly using network-based approaches. These methods are now available in the R packages BioNERO and cageminer, both available on Bioconductor. We then used these methods to identify and prioritize candidate genes involved in resistance to biotic stresses caused by multiple pathogens and pests. At the same time, I was also leading the implementation of a much larger and better version of the Soybean Expression Atlas, now with &gt;5000 samples. After ~5 years under the mentorship of Dr. Thiago Venancio, I was already a well-rounded and experienced bioinformatician at the end of my Master’s.\n\nIn February 2022, I moved to Belgium to start my PhD in Bioinformatics at Ghent University under the supervision of Dr. Yves Van de Peer, at the VIB Center for Plant Systems Biology. Since then, I’ve been studying the impact of gene and genome duplications on plant gene regulatory networks. For that, I use a combination of different approaches, including evolutionary genomics, high-dimensional (mostly transcriptomic) data analyses, and network science. Besides, I often find myself in a position where I cannot find software tools to do what I want, so I end up developing such tools myself. I am the developer and maintainer of &gt;10 R packages, most of them available on Bioconductor, as well as web applications.\n\n\n\n\nAerial footage of the Technology Park in Ghent. Highlighted in the middle (in white/blue and gray) are the buildings of the VIB Center for Plant Systems Biology, where the Van de Peer lab is physically located. The Technology Park also hosts other Ghent University buildings, VIB centers, and biotech/pharma companies such as BASF, Sanofi, and Syngenta."
  },
  {
    "objectID": "teaching/index.html",
    "href": "teaching/index.html",
    "title": "Teaching",
    "section": "",
    "text": "Since 2023, I teach practical lessons in the following courses at Ghent University:\n\nC003709A - Evolutionary Biology, Master’s program in Bioinformatics\nC000500A - Bioinformatics 2, Master’s program in Biochemistry and Biotechnology.\n\n\nBelow is a list of short courses (from 2 days to a week) I have taught."
  },
  {
    "objectID": "teaching/index.html#ugent-courses",
    "href": "teaching/index.html#ugent-courses",
    "title": "Teaching",
    "section": "",
    "text": "Since 2023, I teach practical lessons in the following courses at Ghent University:\n\nC003709A - Evolutionary Biology, Master’s program in Bioinformatics\nC000500A - Bioinformatics 2, Master’s program in Biochemistry and Biotechnology.\n\n\nBelow is a list of short courses (from 2 days to a week) I have taught."
  },
  {
    "objectID": "teaching/index.html#section",
    "href": "teaching/index.html#section",
    "title": "Teaching",
    "section": "2025",
    "text": "2025\n\nBioconductor Kenya workshop -📍 Nairobi, Kenya"
  },
  {
    "objectID": "teaching/index.html#section-1",
    "href": "teaching/index.html#section-1",
    "title": "Teaching",
    "section": "2024",
    "text": "2024\n\nNetwork Analysis in Systems Biology with R/Bioconductor - 📍 Online\nNetwork Analysis in R - 📍 Online\nAnalysis and interpretation of bulk RNA-seq data using Bioconductor - 📍 Oxford, United Kingdom\nSingle-cell RNA-seq analysis with R/Bioconductor, 📍 Online"
  },
  {
    "objectID": "teaching/index.html#section-2",
    "href": "teaching/index.html#section-2",
    "title": "Teaching",
    "section": "2023",
    "text": "2023\n\nNetwork Analysis in Systems Biology with R/Bioconductor - 📍 Online\nAnalysis and interpretation of bulk RNA-seq data using Bioconductor -📍 Ghent, Belgium"
  },
  {
    "objectID": "blog/2021-12-01-push_image_dockerhub/index.html",
    "href": "blog/2021-12-01-push_image_dockerhub/index.html",
    "title": "Pushing Docker images to Docker Hub",
    "section": "",
    "text": "This post assumes you already have an account on Docker Hub. If you don’t, sign up for free before going any further.\nOnce you have a Docker Hub account, log in and create the repository where you want to store the image. You can do that by clicking the Create Repository button.\n\n\n\n\n\n\n\n\n\n\n\nTo push an image to Docker Hub, you will need to have it on your machine. An image can be built from instructions in a Dockerfile or using Docker Compose. Personally, I like to create images from Dockerfiles, where I define my desired OS with all softwares and packages I need. Assuming you alrady have a Dockerfile, cd to the directory where the Dockerfile is and run:\n\ndocker build -t username/reponame .\n\nHere, username and reponame are your Docker Hub’s user name and the name of the repository where you want to store the image.\n\n\n\nTo push your image, you must be logged in. To log in, run:\n\ndocker login\n\nYou will be asked to type your user name and password, and then you’re all set. Finally, push the image with:\n\ndocker push username/reponame:tag\n\nNote that the :tag is not mandatory. If you omit it, a tag latest will be automatically assigned. You would want to assign a custom tag if you’re pushing a specific version of your image. For example, suppose I want to push the version 2.0 of an image to my soyfungigcn repo. To do that, I would run:\n\ndocker push almeidasilvaf/soyfungigcn:2.0\n\nAnd that’s it! In the future, if you want to use that same image on a different machine, all you need to do is run:\n\ndocker pull username/reponame\n\nThis will download the latest version of the image to your machine. You can also specify a specific version to download by setting a :tag after the repository name."
  },
  {
    "objectID": "blog/2021-12-01-push_image_dockerhub/index.html#pushing-docker-images-to-docker-hub",
    "href": "blog/2021-12-01-push_image_dockerhub/index.html#pushing-docker-images-to-docker-hub",
    "title": "Pushing Docker images to Docker Hub",
    "section": "",
    "text": "This post assumes you already have an account on Docker Hub. If you don’t, sign up for free before going any further.\nOnce you have a Docker Hub account, log in and create the repository where you want to store the image. You can do that by clicking the Create Repository button.\n\n\n\n\n\n\n\n\n\n\n\nTo push an image to Docker Hub, you will need to have it on your machine. An image can be built from instructions in a Dockerfile or using Docker Compose. Personally, I like to create images from Dockerfiles, where I define my desired OS with all softwares and packages I need. Assuming you alrady have a Dockerfile, cd to the directory where the Dockerfile is and run:\n\ndocker build -t username/reponame .\n\nHere, username and reponame are your Docker Hub’s user name and the name of the repository where you want to store the image.\n\n\n\nTo push your image, you must be logged in. To log in, run:\n\ndocker login\n\nYou will be asked to type your user name and password, and then you’re all set. Finally, push the image with:\n\ndocker push username/reponame:tag\n\nNote that the :tag is not mandatory. If you omit it, a tag latest will be automatically assigned. You would want to assign a custom tag if you’re pushing a specific version of your image. For example, suppose I want to push the version 2.0 of an image to my soyfungigcn repo. To do that, I would run:\n\ndocker push almeidasilvaf/soyfungigcn:2.0\n\nAnd that’s it! In the future, if you want to use that same image on a different machine, all you need to do is run:\n\ndocker pull username/reponame\n\nThis will download the latest version of the image to your machine. You can also specify a specific version to download by setting a :tag after the repository name."
  },
  {
    "objectID": "blog/2022-05-06-upgrading_R/index.html",
    "href": "blog/2022-05-06-upgrading_R/index.html",
    "title": "Upgrading R version with all your packages",
    "section": "",
    "text": "Have you ever upgraded R and lost all of your packages? As a consequence, you had to install them again one by one. One. By. One. Oh, man… Boring, huh? Here, I will guide you on how to upgrade your R version and reinstall your packages automatically. This way, you can spend your time on what really matters: writing some cool R code! This post is inspired by this Gist code."
  },
  {
    "objectID": "blog/2022-05-06-upgrading_R/index.html#motivation",
    "href": "blog/2022-05-06-upgrading_R/index.html#motivation",
    "title": "Upgrading R version with all your packages",
    "section": "",
    "text": "Have you ever upgraded R and lost all of your packages? As a consequence, you had to install them again one by one. One. By. One. Oh, man… Boring, huh? Here, I will guide you on how to upgrade your R version and reinstall your packages automatically. This way, you can spend your time on what really matters: writing some cool R code! This post is inspired by this Gist code."
  },
  {
    "objectID": "blog/2022-05-06-upgrading_R/index.html#taking-a-picture-of-your-current-r-package-universe",
    "href": "blog/2022-05-06-upgrading_R/index.html#taking-a-picture-of-your-current-r-package-universe",
    "title": "Upgrading R version with all your packages",
    "section": "‘Taking a picture’ of your current R package universe",
    "text": "‘Taking a picture’ of your current R package universe\nThe first thing you need to do before upgrading your R version is to save a list of all packages you have installed. Not only must you have package names, but also from where they were downloaded (e.g., CRAN, Bioconductor, GitHub, etc.). The code below will create a data frame of packages and their sources, and save it as a .csv file in your current working directory.\nNOTE: You need to have the packages tidyverse and sessioninfo installed.\n\n#----Create a data frame with all installed packages and their sources---------\nlibrary(tidyverse)\nall_pkg &lt;- sessioninfo::session_info(\"installed\") |&gt; \n  pluck(\"packages\") |&gt; \n  as_tibble()\n\n# Classify sources: CRAN, Bioconductor, GitHub, r-universe, and local\nsplit_repo &lt;- all_pkg |&gt; \n    mutate(repo = case_when(\n        str_detect(source, \"Bioconductor\") ~ \"Bioconductor\",\n        str_detect(source, \"CRAN\") ~ \"CRAN\",\n        str_detect(source, \"Github\") ~ \"GitHub\",\n        str_detect(source, \"local\") ~ \"local\",\n        str_detect(source, \"r-universe\") ~ \"r-universe\",\n        TRUE ~ NA_character_\n    ), .before = \"source\") |&gt;\n    select(package, repo)\n\nhead(split_repo)\n\n# A tibble: 6 × 2\n  package repo        \n  &lt;chr&gt;   &lt;chr&gt;       \n1 abind   CRAN        \n2 ade4    CRAN        \n3 afex    CRAN        \n4 affy    Bioconductor\n5 affyio  Bioconductor\n6 airway  Bioconductor\n\n\nYou can then export this data frame to a .csv file as follows:\n\nsplit_repo |&gt; \n  write_csv(\"packages.csv\")\n\nNow that you have a list of all your packages and their sources, you can install the latest version of R. That will vary according to the operating system you use, so you’d better go to the CRAN page and see the instructions on how to upgrade R for your case. In my case, on a Ubuntu 20.04 LTS machine, I just ran:\n\nsudo apt-get update\nsudo apt-get upgrade\n\nOnce you’re done upgrading your R version, open a new R session (now with the latest version) and run the following code to install all your beloved packages:\n\n#----First, install tidyverse, remotes, and BiocManager-------------------------\nif(!require(\"tidyverse\", quietly = TRUE))\n    install.packages(\"tidyverse\")\n\nif(!require(\"remotes\", quietly = TRUE))\n    install.packages(\"remotes\")\n\nif(!require(\"BiocManager\", quietly = TRUE))\n    install.packages(\"BiocManager\")\n\n#----Read data frame with package names and sources-----------------------------\nlibrary(tidyverse)\nall_pkg &lt;- readr::read_csv(\"packages.csv\", show_col_types = FALSE)\n\n#----Reinstall packages---------------------------------------------------------\n## CRAN packages\ncran_pkg &lt;- all_pkg |&gt; \n  dplyr::filter(repo == \"CRAN\") |&gt; \n  dplyr::pull(package)\n\ncran_pkg |&gt;\n  install.packages()\n\n\n## Bioconductor packages\nbioc_pkg &lt;- all_pkg |&gt;\n    dplyr::filter(repo == \"Bioconductor\") |&gt;\n    dplyr::pull(package)\n\nbioc_pkg |&gt;\n    BiocManager::install()\n\n\n## R-Universe\nruni_pkg &lt;- all_pkg |&gt;\n    dplyr::filter(repo == \"r-universe\") |&gt;\n    dplyr::pull(package)\n\nruni_pkg |&gt;\n    install.packages(repos = \"https://ropensci.r-universe.dev\")\n\n\n## GitHub packages - only list packages\ngh_pkg &lt;- all_pkg |&gt;\n    dplyr::filter(repo == \"GitHub\") |&gt;\n    dplyr::pull(package)\n\nFor GitHub packages, I suggest looking at them one by one (there shouldn’t be many of them) and deciding which ones you want to install, as many of them are usually unstable and installed for testing purposes. Once you have identified which ones you want to install, you can do it with remotes::install_github().\nAnd that’s all! Whenever you need to upgrade R, just run the same code again and you’re all set. I hope this post helped you!"
  },
  {
    "objectID": "blog/2022-05-06-upgrading_R/index.html#session-information",
    "href": "blog/2022-05-06-upgrading_R/index.html#session-information",
    "title": "Upgrading R version with all your packages",
    "section": "Session information",
    "text": "Session information\n\nsessioninfo::session_info()\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.1 (2024-06-14)\n os       Ubuntu 22.04.4 LTS\n system   x86_64, linux-gnu\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/Brussels\n date     2025-06-06\n pandoc   3.2 @ /usr/lib/rstudio/resources/app/bin/quarto/bin/tools/x86_64/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n bit           4.0.5   2022-11-15 [1] CRAN (R 4.4.1)\n bit64         4.0.5   2020-08-30 [1] CRAN (R 4.4.1)\n cli           3.6.3   2024-06-21 [1] CRAN (R 4.4.1)\n colorspace    2.1-0   2023-01-23 [1] CRAN (R 4.4.1)\n crayon        1.5.3   2024-06-20 [1] CRAN (R 4.4.1)\n digest        0.6.36  2024-06-23 [1] CRAN (R 4.4.1)\n dplyr       * 1.1.4   2023-11-17 [1] CRAN (R 4.4.1)\n evaluate      0.24.0  2024-06-10 [1] CRAN (R 4.4.1)\n fastmap       1.2.0   2024-05-15 [1] CRAN (R 4.4.1)\n forcats     * 1.0.0   2023-01-29 [1] CRAN (R 4.4.1)\n generics      0.1.3   2022-07-05 [1] CRAN (R 4.4.1)\n ggplot2     * 3.5.1   2024-04-23 [1] CRAN (R 4.4.1)\n glue          1.8.0   2024-09-30 [1] https://cran.r-universe.dev (R 4.4.1)\n gtable        0.3.5   2024-04-22 [1] CRAN (R 4.4.1)\n hms           1.1.3   2023-03-21 [1] CRAN (R 4.4.1)\n htmltools     0.5.8.1 2024-04-04 [1] CRAN (R 4.4.1)\n htmlwidgets   1.6.4   2023-12-06 [1] CRAN (R 4.4.1)\n jsonlite      1.8.8   2023-12-04 [1] CRAN (R 4.4.1)\n knitr         1.48    2024-07-07 [1] CRAN (R 4.4.1)\n lifecycle     1.0.4   2023-11-07 [1] CRAN (R 4.4.1)\n lubridate   * 1.9.3   2023-09-27 [1] CRAN (R 4.4.1)\n magrittr      2.0.3   2022-03-30 [1] CRAN (R 4.4.1)\n munsell       0.5.1   2024-04-01 [1] CRAN (R 4.4.1)\n pillar        1.10.2  2025-04-05 [1] https://cran.r-universe.dev (R 4.4.1)\n pkgconfig     2.0.3   2019-09-22 [1] CRAN (R 4.4.1)\n purrr       * 1.0.2   2023-08-10 [1] CRAN (R 4.4.1)\n R6            2.5.1   2021-08-19 [1] CRAN (R 4.4.1)\n readr       * 2.1.5   2024-01-10 [1] CRAN (R 4.4.1)\n rlang         1.1.4   2024-06-04 [1] CRAN (R 4.4.1)\n rmarkdown     2.27    2024-05-17 [1] CRAN (R 4.4.1)\n rstudioapi    0.16.0  2024-03-24 [1] CRAN (R 4.4.1)\n scales        1.3.0   2023-11-28 [1] CRAN (R 4.4.1)\n sessioninfo   1.2.2   2021-12-06 [1] CRAN (R 4.4.1)\n stringi       1.8.4   2024-05-06 [1] CRAN (R 4.4.1)\n stringr     * 1.5.1   2023-11-14 [1] CRAN (R 4.4.1)\n tibble      * 3.2.1   2023-03-20 [1] CRAN (R 4.4.1)\n tidyr       * 1.3.1   2024-01-24 [1] CRAN (R 4.4.1)\n tidyselect    1.2.1   2024-03-11 [1] CRAN (R 4.4.1)\n tidyverse   * 2.0.0   2023-02-22 [1] CRAN (R 4.4.1)\n timechange    0.3.0   2024-01-18 [1] CRAN (R 4.4.1)\n tzdb          0.4.0   2023-05-12 [1] CRAN (R 4.4.1)\n utf8          1.2.4   2023-10-22 [1] CRAN (R 4.4.1)\n vctrs         0.6.5   2023-12-01 [1] CRAN (R 4.4.1)\n vroom         1.6.5   2023-12-05 [1] CRAN (R 4.4.1)\n withr         3.0.0   2024-01-16 [1] CRAN (R 4.4.1)\n xfun          0.51    2025-02-19 [1] CRAN (R 4.4.1)\n yaml          2.3.9   2024-07-05 [1] CRAN (R 4.4.1)\n\n [1] /home/faalm/R/x86_64-pc-linux-gnu-library/4.4\n [2] /usr/local/lib/R/site-library\n [3] /usr/lib/R/site-library\n [4] /usr/lib/R/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "publications/index.html",
    "href": "publications/index.html",
    "title": "My publications",
    "section": "",
    "text": "Almeida-Silva F, Van de Peer Y (2025). “Gene expression divergence following gene and genome duplications in spatially resolved plant transcriptomes.” bioRxiv, 2025-05. 🔗\nTaheri A, Almeida-Silva F, Zhang Y, Fu X, Li L, Wang Y, Tang K (2025). “Artemisia Database: A Comprehensive Resource for Gene Expression and Functional Insights in Artemisia annua.” bioRxiv, 2025-05. 🔗\nOlvera-Vazquez SG, Chen X, Mesnil A, Meslin C, Almeida-Silva F, Confais J, Bourgeois Y, Lougmani C, Alix K, Choisne N, others (2025). “Comprehensive annotation of olfactory and gustatory receptor genes and transposable elements revealed their evolutionary dynamics in aphids.” bioRxiv, 2025-04. 🔗\nChen H, Almeida-Silva F, Logghe G, Bonte D, Van de Peer Y (2024). “The rise of polyploids during environmental catastrophes.” bioRxiv, 2024-11. 🔗"
  },
  {
    "objectID": "publications/index.html#preprints-awaiting-peer-review",
    "href": "publications/index.html#preprints-awaiting-peer-review",
    "title": "My publications",
    "section": "",
    "text": "Almeida-Silva F, Van de Peer Y (2025). “Gene expression divergence following gene and genome duplications in spatially resolved plant transcriptomes.” bioRxiv, 2025-05. 🔗\nTaheri A, Almeida-Silva F, Zhang Y, Fu X, Li L, Wang Y, Tang K (2025). “Artemisia Database: A Comprehensive Resource for Gene Expression and Functional Insights in Artemisia annua.” bioRxiv, 2025-05. 🔗\nOlvera-Vazquez SG, Chen X, Mesnil A, Meslin C, Almeida-Silva F, Confais J, Bourgeois Y, Lougmani C, Alix K, Choisne N, others (2025). “Comprehensive annotation of olfactory and gustatory receptor genes and transposable elements revealed their evolutionary dynamics in aphids.” bioRxiv, 2025-04. 🔗\nChen H, Almeida-Silva F, Logghe G, Bonte D, Van de Peer Y (2024). “The rise of polyploids during environmental catastrophes.” bioRxiv, 2024-11. 🔗"
  },
  {
    "objectID": "publications/index.html#section",
    "href": "publications/index.html#section",
    "title": "My publications",
    "section": "2025",
    "text": "2025\n26. Zhang R, Shang H, Milne RI, Almeida-Silva F, Chen H, Zhou M, Shu H, Jia K, Van de Peer Y, Ma Y (2025). “SOI: robust identification of orthologous synteny with the Orthology Index and broad applications in evolutionary genomics.” Nucleic Acids Research, 53(7), gkaf320. 🔗\n25. Drnevich J, Tan FJ, Almeida-Silva F, Castelo R, Culhane AC, Davis S, Doyle MA, Holmes S, Lahti L, Mahmoud A, Nishida K, Ramos M, Rue-Albrecht K, Shih DJH, Gatto L, Soneson C (2025). “Learning and teaching biological data science in the Bioconductor community.” PLoS Computational Biology. 🔗\n24. Almeida-Silva F, Van de Peer Y (2025). “doubletrouble: an R/Bioconductor package for the identification, classification, and analysis of gene and genome duplications.” Bioinformatics, btaf043. 🔗"
  },
  {
    "objectID": "publications/index.html#section-1",
    "href": "publications/index.html#section-1",
    "title": "My publications",
    "section": "2024",
    "text": "2024\n23. Prost-Boxoen L, Bafort Q, Van de Vloet A, Almeida-Silva F, Paing YT, Casteleyn G, D’hondt S, De Clerck O, Van de Peer Y (2024). “Asymmetric genome merging leads to gene expression novelty through nucleo-cytoplasmic disruptions and transcriptomic shock in Chlamydomonas triploids.” New Phytologist. 🔗\n22. Barbosa-Xavier K, Pedrosa-Silva F, Almeida-Silva F, Venancio TM (2024). “Cannabis Expression Atlas: a comprehensive resource for integrative analysis of Cannabis sativa L. gene expression.” Physiologia Plantarum, 176(6), e70010. 🔗\n21. Turquetti-Moraes DK, Cardoso-Silva CB, Almeida-Silva F, Venancio TM (2024). “Multiomic analysis of genes related to oil traits in legumes provide insights into lipid metabolism and oil richness in soybean.” Plant Physiology and Biochemistry, 109180. ISSN 0981-9428, 🔗\n20. Wu T, Bafort Q, Mortier F, Almeida-Silva F, Natran A, Van de Peer Y (2024). “The immediate metabolomic effects of whole-genome duplication in the greater duckweed, Spirodela polyrhiza.” American Journal of Botany, e16383. 🔗\n19. Almeida-Silva F, Prost-Boxoen L, Van de Peer Y (2024). “hybridexpress: an R/Bioconductor package for comparative transcriptomic analyses of hybrids and their progenitors.” New Phytologist, 243(2), 811-819. 🔗"
  },
  {
    "objectID": "publications/index.html#section-2",
    "href": "publications/index.html#section-2",
    "title": "My publications",
    "section": "2023",
    "text": "2023\n18. Pinto VB, Vidigal PMP, Dal-Bianco M, Almeida-Silva F, Venancio TM, Viana JMS (2023). “Transcriptome-based strategies for identifying aluminum tolerance genes in popcorn (Zea mays L. var. everta).” Scientific Reports, 13(1), 19400. 🔗\n17. Cherene MB, Taveira GB, Almeida-Silva F, da Silva MS, Cavaco MC, da Silva-Ferreira AT, Perales JEA, de Oliveira Carvalho A, Venâncio TM, da Motta OV, others (2023). “Structural and Biochemical Characterization of Three Antimicrobial Peptides from Capsicum annuum L. var. annuum Leaves for Anti-Candida Use.” Probiotics and Antimicrobial Proteins, 1-18. 🔗\n16. Cao Y, Almeida-Silva F, Zhang W, Ding Y, Bai D, Bai W, Zhang B, Van de Peer Y, Zhang D (2023). “Genomic Insights into Adaptation to Karst Limestone and Incipient Speciation in East Asian Platycarya spp.(Juglandaceae).” Molecular Biology and Evolution, 40(6), msad121. 🔗\n15. Almeida-Silva F, Venancio TM (2023). “Discovering and prioritizing candidate resistance genes against soybean pests by integrating GWAS and gene coexpression networks.” Gene, 860, 147231. 🔗\n14. Almeida-Silva F, Pedrosa-Silva F, Venancio TM (2023). “The Soybean Expression Atlas v2: A comprehensive database of over 5000 RNA-seq samples.” The Plant Journal. 🔗\n13. Almeida-Silva F, Van de Peer Y (2023). “Assessing the quality of comparative genomics data and results with the cogeqc R/Bioconductor package.” Methods in Ecology and Evolution. 🔗\n12. Almeida-Silva F, Van de Peer Y (2023). “Whole-genome Duplications and the Long-term Evolution of Gene Regulatory Networks in Angiosperms.” Molecular Biology and Evolution, 40(7), msad141. 🔗\n11. Almeida-Silva F, Zhao T, Ullrich KK, Schranz ME, Van de Peer Y (2023). “syntenet: an R/Bioconductor package for the inference and analysis of synteny networks.” Bioinformatics, 39(1), btac806. 🔗"
  },
  {
    "objectID": "publications/index.html#section-3",
    "href": "publications/index.html#section-3",
    "title": "My publications",
    "section": "2022",
    "text": "2022\n10. Irineu LESdS, Soares CdP, Soares TS, Almeida FAd, Almeida-Silva F, Gazara RK, Meneses CHSG, Canellas LP, Silveira V, Venancio TM, others (2022). “Multiomic approaches reveal hormonal modulation and nitrogen uptake and assimilation in the initial growth of maize inoculated with Herbaspirillum seropedicae.” Plants, 12(1), 48. 🔗\n9. Almeida-Silva F, Venancio TM (2022). “BioNERO: an all-in-one R/Bioconductor package for comprehensive and easy biological network reconstruction.” Functional & Integrative Genomics, 22(1), 131-136. 🔗\n8. Almeida-Silva F, Venancio TM (2022). “Pathogenesis-related protein 1 (PR-1) genes in soybean: Genome-wide identification, structural analysis and expression profiling under multiple biotic and abiotic stresses.” Gene, 809, 146013. 🔗\n7. Turquetti-Moraes DK, Moharana KC, Almeida-Silva F, Pedrosa-Silva F, Venancio TM (2022). “Integrating omics approaches to discover and prioritize candidate genes involved in oil biosynthesis in soybean.” Gene, 808, 145976. 🔗\n6. Almeida-Silva F, Venancio TM (2022). “cageminer: an R/Bioconductor package to prioritize candidate genes by integrating genome-wide association studies and gene coexpression networks.” in silico Plants, 4(2), diac018. 🔗"
  },
  {
    "objectID": "publications/index.html#section-4",
    "href": "publications/index.html#section-4",
    "title": "My publications",
    "section": "2021",
    "text": "2021\n5. Almeida-Silva F, Venancio TM (2021). “Integration of genome-wide association studies and gene coexpression networks unveils promising soybean resistance genes against five common fungal pathogens.” Scientific Reports, 11(1), 24453. 🔗\n4. Sangi S, Araújo PM, Coelho FS, Gazara RK, Almeida-Silva F, Venancio TM, Grativol C (2021). “Genome-wide analysis of the COBRA-Like gene family supports gene expansion through Whole-Genome Duplication in soybean (Glycine max).” Plants, 10(1), 167. 🔗\n3. Almeida-Silva F, Moharana KC, Venancio TM (2021). “The state of the art in soybean transcriptomics resources and gene coexpression networks.” in silico Plants, 3(1), diab005. 🔗"
  },
  {
    "objectID": "publications/index.html#section-5",
    "href": "publications/index.html#section-5",
    "title": "My publications",
    "section": "2020",
    "text": "2020\n2. Almeida-Silva F, Moharana KC, Machado FB, Venancio TM (2020). “Exploring the complexity of soybean (Glycine max) transcriptional regulation using global gene co-expression networks.” Planta, 252, 1-12. 🔗\n1. Machado FB, Moharana KC, Almeida-Silva F, Gazara RK, Pedrosa-Silva F, Coelho FS, Grativol C, Venancio TM (2020). “Systematic analysis of 1298 RNA-Seq samples and construction of a comprehensive soybean (Glycine max) expression atlas.” The Plant Journal, 103(5), 1894-1909. 🔗"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hi, I’m Fabrício!",
    "section": "",
    "text": "I am a PhD student in Bioinformatics at Ghent University (Belgium) supervised by Dr. Yves Van de Peer, and I conduct my research at the VIB Center for Plant Systems Biology. I am particularly interested in using and developing network-based approaches to explore the impact of gene and genome duplications on the evolution of plant genomes and regulatory networks.\nAs an advocate for open science and reproducible research, I have contributed to the Bioconductor project with several R packages. I am also an active member of the Bioconductor training commitee, where I contribute by developing Bioconductor-focused training materials and teaching Bioconductor Carpentry workshops."
  },
  {
    "objectID": "talks/sbv2021/index.html",
    "href": "talks/sbv2021/index.html",
    "title": "Bioinformatics in Modern Biology: computational genomics as a tool to unravel the soybean genome and gene regulation",
    "section": "",
    "text": "Click here to access the slide presentation."
  },
  {
    "objectID": "talks/sbv2021/index.html#overview",
    "href": "talks/sbv2021/index.html#overview",
    "title": "Bioinformatics in Modern Biology: computational genomics as a tool to unravel the soybean genome and gene regulation",
    "section": "",
    "text": "Click here to access the slide presentation."
  },
  {
    "objectID": "talks/bioc2021/index.html",
    "href": "talks/bioc2021/index.html",
    "title": "cageminer: mining candidate genes by integrating GWAS and gene coexpression networks",
    "section": "",
    "text": "Click here to access the slide presentation."
  },
  {
    "objectID": "talks/bioc2021/index.html#overview",
    "href": "talks/bioc2021/index.html#overview",
    "title": "cageminer: mining candidate genes by integrating GWAS and gene coexpression networks",
    "section": "",
    "text": "Click here to access the slide presentation."
  }
]